{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from helper import set_seeds, create_folder_if_it_doesnt_exist, get_x_test,  calculate_test_results, REAL_DATA, SYN_DATA\n",
    "from plot_helper import get_folder_name_from_args, plot_results_during_training,\\\n",
    "        display_final_results, display_results, VANILLA_QR, OQR_CORR, OQR_HSIC\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seeds = range(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal QR: Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display During Training Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run `python run_all_synthetic_data_experiments.py` in the folder `reproducible_experiments` to receive all during traning results of the synthetic data\n",
    "### Alternatively, run main.py with the flag: `--save_training_results 1` to save the results of the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_type = SYN_DATA\n",
    "data_name = '3'\n",
    "\n",
    "results_dir = f'results/during_training/{data_type.replace(\" \", \"_\")}/{data_name}/'\n",
    "\n",
    "result_during_training_name = (results_dir + \"results_during_training\").replace(\" \", \"_\")\n",
    "results_during_training = pickle.load(open(result_during_training_name, \"rb\"))\n",
    "\n",
    "print(f\"Possible args to choose from: {list(results_during_training.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_name = 'loss=batch_qr_bs=1024_corr_mult=0.0_hsic_mult=0.0'\n",
    "print(f\"Possible seed values to choose from: {list(results_during_training[args_name].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "curr_results_during_training = results_during_training[args_name][seed_value]\n",
    "\n",
    "alpha = 0.1\n",
    "mpl.rc('font', **{'size'   : 13})\n",
    "\n",
    "line_width = 2\n",
    "save_dir = f'./results/figures/syn/during_training/seed={seed_value}'\n",
    "create_folder_if_it_doesnt_exist(save_dir)\n",
    "\n",
    "if 'corr_mult=0.0' in args_name:\n",
    "    majority_title = \"Majority Group (vanilla QR)\"\n",
    "    minority_title = \"Minority Group (vanilla QR)\"\n",
    "    last_epoch_to_present = len(curr_results_during_training['coverage_over_train_group_0']) - 1\n",
    "else:\n",
    "    majority_title = \"Majority Group (orthogonal QR)\"\n",
    "    minority_title = \"Minority Group (orthogonal QR)\"\n",
    "    last_epoch_to_present = len(curr_results_during_training['coverage_over_train_group_0']) -1 # - 200 + 10\n",
    "\n",
    "\n",
    "desired_accuracy = 1-alpha\n",
    "\n",
    "plt.plot(curr_results_during_training['coverage_over_train_group_0'][:last_epoch_to_present], label=\"Train\", linewidth=line_width)\n",
    "plt.plot(curr_results_during_training['coverage_over_test_group_0'][:last_epoch_to_present], label=\"Test\", linewidth=line_width)\n",
    "plt.axhline(y=desired_accuracy, color='r', linestyle='--',  label=\"Nominal Coverage Level\")\n",
    "plt.axvline(len(curr_results_during_training['coverage_over_train_group_0']) - 200, color='purple',  linestyle='-', label=\"Best Epoch\")\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "plt.title(majority_title)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Coverage\")\n",
    "plt.savefig(f'{save_dir}/{majority_title}.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(curr_results_during_training['coverage_over_train_group_1'][:last_epoch_to_present], label=\"Train\", linewidth=line_width)\n",
    "plt.plot(curr_results_during_training['coverage_over_test_group_1'][:last_epoch_to_present], label=\"Test\", linewidth=line_width)\n",
    "plt.axhline(y=desired_accuracy, color='r', linestyle='--', label=\"Nominal Coverage Level\")\n",
    "plt.axvline(len(curr_results_during_training['coverage_over_train_group_1']) - 200, color='purple',  linestyle='-', label=\"Best Epoch\")\n",
    "\n",
    "\n",
    "plt.title(minority_title)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Coverage\")\n",
    "plt.savefig(f'{save_dir}/{minority_title}.png', dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('majority train coverage: {:.2f}, majority test coverage: {:.2f}'.\n",
    "      format(curr_results_during_training['coverage_over_train_group_0'][-201]*100,\n",
    "      curr_results_during_training['coverage_over_test_group_0'][-201]*100))\n",
    "\n",
    "print('majority train avg length: {:.2f}, majority test avg length: {:.2f}'.\n",
    "      format(curr_results_during_training['interval_lengths_over_train_group_0'][-201],\n",
    "      curr_results_during_training['interval_lengths_over_test_group_0'][-201]))\n",
    "print()\n",
    "\n",
    "print('minority train: {:.2f}, minority test: {:.2f}'.\n",
    "      format(curr_results_during_training['coverage_over_train_group_1'][-201]*100,\n",
    "      curr_results_during_training['coverage_over_test_group_1'][-201]*100))\n",
    "\n",
    "\n",
    "print('minority train avg length: {:.2f}, minority test avg length: {:.2f}'.\n",
    "      format(curr_results_during_training['interval_lengths_over_train_group_1'][-201],\n",
    "      curr_results_during_training['interval_lengths_over_test_group_1'][-201]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Results - averaged over 30 seeds\n",
    "\n",
    "### Run `python run_all_synthetic_data_experiments.py` in the folder `reproducible_experiments` to receive all results of the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "possible loss_method = ['qr,' 'int']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "display_results(['3', '10'], loss_method='qr',\n",
    "                              corr_multipliers=[0.,0.5], hsic_multipliers=[0.], \n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=False, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('qr', 'Vanilla QR', 'OQR (corr)', is_real=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval score loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(['3', '10'], loss_method='int', corr_multipliers=[0., 3.], hsic_multipliers=[0.],\n",
    "                is_real=False, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('int', 'Vanilla QR', 'OQR (corr)', is_real=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted QR (pinball loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(['3', '10'], loss_method='wqr',\n",
    "                              corr_multipliers=[0.,0.5], hsic_multipliers=[0.], \n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=False, print_latex=False)\n",
    "styled_final_df = display_final_results('wqr', baseline_method='Vanilla WQR', improved_method='OWQR (corr)',\n",
    "                                        is_real=False, to_latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Dataset Results - averaged over 30 seeds\n",
    "### Run `python run_all_real_data_experiments.py` in the folder `reproducible_experiments` to receive all results of the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_dataset_names = ['facebook_1', 'facebook_2','blog_data', 'bio',\\\n",
    "                 'kin8nm', 'naval','meps_19', 'meps_20', 'meps_21']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "possible dataset_names = ['facebook_1', 'facebook_2','blog_data', 'bio',\\\n",
    "                 'kin8nm', 'naval','meps_19', 'meps_20', 'meps_21']\n",
    "   \n",
    "possible loss_method = ['qr,' 'int']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dataset_names = ['facebook_1', 'facebook_2','blog_data', 'bio',\\\n",
    "                 'kin8nm', 'naval','meps_19', 'meps_20', 'meps_21']\n",
    "\n",
    "display_results(dataset_names, loss_method='qr',\n",
    "                              corr_multipliers=[0., 0.1, 0.5], hsic_multipliers=[0.], \n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=True, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('qr', baseline_method='Vanilla QR', improved_method='OQR (corr)', is_real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval score loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names = possible_dataset_names\n",
    "\n",
    "display_results(dataset_names, loss_method='int',\n",
    "                              corr_multipliers=[0., 0.1, 0.5, 1., 3.], hsic_multipliers=[0.], \n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=True, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('int', baseline_method='Vanilla QR', improved_method='OQR (corr)', is_real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted QR (pinball loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names = ['facebook_1', 'facebook_2','blog_data', 'bio',\\\n",
    "                 'kin8nm', 'naval','meps_19', 'meps_20', 'meps_21']\n",
    "\n",
    "\n",
    "display_results(dataset_names, loss_method='wqr',\n",
    "                              corr_multipliers=[0., 0.1, 0.5], hsic_multipliers=[0.], \n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=True, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('wqr', baseline_method='Vanilla WQR', improved_method='OWQR (corr)', is_real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinball loss and HSIC\n",
    "### Vanilla QR vs Orthogonal QR (with pinball loss and HSIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names =possible_dataset_names\n",
    "\n",
    "display_results(dataset_names, loss_method='qr',\n",
    "                              corr_multipliers=[0.], hsic_multipliers=[0., 0.1, 0.5], \n",
    "                              base_method=VANILLA_QR, improved_method=OQR_HSIC,\n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=True, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('qr', baseline_method='Vanilla QR', improved_method='OQR (HSIC)', is_real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Orthogonal QR (with pinball loss and HSIC) vs  Orthogonal QR (with pinball loss and decorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names = possible_dataset_names\n",
    "\n",
    "\n",
    "display_results(dataset_names, loss_method='qr',\n",
    "                              corr_multipliers=[0., 0.1, 0.5], hsic_multipliers=[0., 0.1, 0.5], \n",
    "                              base_method=OQR_HSIC, improved_method=OQR_CORR,\n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=True, print_latex=False)\n",
    "\n",
    "styled_final_df = display_final_results('qr', baseline_method='OQR (HSIC)',\n",
    "                                        improved_method='OQR (corr)', is_real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformalized Quantile Regression (pinball loss)\n",
    "## Vanilla CQR vs Orthogonal CQR (decorrelation penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names = possible_dataset_names\n",
    "\n",
    "\n",
    "display_results(dataset_names, loss_method='qr',\n",
    "                              corr_multipliers=[0., 0.1, 0.5], hsic_multipliers=[0.], \n",
    "                              seeds=seeds, desired_coverage=0.9, is_calibrated=True, is_real=True)\n",
    "\n",
    "styled_final_df = display_final_results('cal_qr', baseline_method='Vanilla CQR',\n",
    "                                        improved_method='OCQR (corr)', is_real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile regression forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "possible dataset_names = ['facebook_1', 'facebook_2','blog_data', 'bio',\\\n",
    "                 'kin8nm', 'naval','meps_19', 'meps_20', 'meps_21']\n",
    "   \n",
    "possible loss_method = ['qr,' 'int']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dataset_names = ['facebook_1', 'blog_data', 'bio',\\\n",
    "                 'kin8nm', 'naval','meps_19', 'meps_20', 'meps_21']\n",
    "\n",
    "display_results(dataset_names, method='qr_forest', \n",
    "                              seeds=seeds,desired_coverage=0.9, is_real=True, print_latex=False, keep_cov_and_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters as a function of regularization multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import pandas as pd\n",
    "from helper import get_method_results_dir\n",
    "import numpy as np\n",
    "\n",
    "method_args = Namespace(\n",
    "    loss='batch_qr',\n",
    "    bs=1024,\n",
    "    hsic_mult=0.0,\n",
    "    method='QR'\n",
    "    )\n",
    "data_name =  \"minority_group_uncertainty=3\"\n",
    "seeds = range(20)\n",
    "corr_mults = [0., 0.1, 0.25, 0.5, 1, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # = gamma\n",
    "\n",
    "total_df = pd.DataFrame()\n",
    "features = ['coverage', 'interval_len', 'interval_len_var', 'test_pearson_corr',  'test_hsic', 'test_wsc_diff']\n",
    "reduction_method = np.mean\n",
    "\n",
    "for corr_mult in corr_mults:\n",
    "    corr_mult = float(corr_mult)\n",
    "    method_args.corr_mult = corr_mult\n",
    "    seeds_df = pd.DataFrame()\n",
    "    for seed in seeds:\n",
    "        results_dir = get_method_results_dir(SYN_DATA, data_name, method_args)\n",
    "        results_path = f\"{results_dir}/seed={seed}.csv\"\n",
    "        df = pd.read_csv(results_path)\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "        df = df[features]\n",
    "        seeds_df = seeds_df.append(df)\n",
    "    seeds_df = seeds_df.apply(reduction_method, axis=0).to_frame(corr_mult)\n",
    "    total_df = total_df.append(seeds_df.T)\n",
    "\n",
    "feature_name_map = {\n",
    "    'coverage': 'Coverage', \n",
    "    'interval_len': 'Avg. length',\n",
    "    'interval_len_var': \"Interval's length variance\", \n",
    "    'test_pearson_corr': \"Pearson's correlation\",  \n",
    "    'test_hsic': \"HSIC\",\n",
    "    'test_wsc_diff': \"ΔWSC\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from helper import get_feature_as_function_of_mult_figure_dir\n",
    "for feature in features:\n",
    "    plt.plot(abs(total_df[feature]))\n",
    "    feature = feature_name_map[feature]\n",
    "    plt.xlabel(\"corr mult\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.title(f\"{feature} vs $\\gamma$\")\n",
    "    save_dir = get_feature_as_function_of_mult_figure_dir(SYN_DATA, data_name, mult=\"corr\", args=method_args)\n",
    "    create_folder_if_it_doesnt_exist(save_dir)\n",
    "    plt.savefig(f\"{save_dir}/{feature}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
